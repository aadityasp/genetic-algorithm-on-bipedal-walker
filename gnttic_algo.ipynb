{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadityasp/Aditya/Projects/FAI_prjt/fai/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0 Score: -100.07884285899841\n",
      "Generation: 1 Score: -99.43141599802453\n",
      "Generation: 2 Score: -100.12341952465209\n",
      "Generation: 3 Score: -96.71923987511293\n",
      "Generation: 4 Score: -99.11920166116651\n",
      "Generation: 5 Score: -98.95568178070114\n",
      "Generation: 6 Score: -98.9472662677985\n",
      "Generation: 7 Score: -98.98570558711113\n",
      "Generation: 8 Score: -88.14688111204111\n",
      "Generation: 9 Score: -88.2564762022554\n",
      "Generation: 10 Score: -84.7208348704939\n",
      "Generation: 11 Score: -83.80718462162089\n",
      "Generation: 12 Score: -79.73696266731592\n",
      "Generation: 13 Score: -77.8271554940249\n",
      "Generation: 14 Score: -71.55715705891731\n",
      "Generation: 15 Score: -74.19425704477463\n",
      "Generation: 16 Score: -70.60125692234821\n",
      "Generation: 17 Score: -72.81263517808607\n",
      "Generation: 18 Score: -73.39610933036901\n",
      "Generation: 19 Score: -72.62448989932314\n",
      "Generation: 20 Score: -60.17841102360952\n",
      "Generation: 21 Score: -50.83967177233018\n",
      "Generation: 22 Score: -53.079412155855096\n",
      "Generation: 23 Score: -43.02773522030149\n",
      "Generation: 24 Score: -52.48782462556789\n",
      "Generation: 25 Score: -38.796501585152704\n",
      "Generation: 26 Score: -38.61967949881057\n",
      "Generation: 27 Score: 5.4382598812903495\n",
      "Generation: 28 Score: 2.9957253875354177\n",
      "Generation: 29 Score: 24.56730191511257\n",
      "Generation: 30 Score: 49.038023042851854\n",
      "Generation: 31 Score: 59.68679280720761\n",
      "Generation: 32 Score: 69.67381080529772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "#weight initializations\n",
    "#uniform_distribution\n",
    "#he_init(uniform and normal)\n",
    "#Xavier/glorot_distribution(normal and uniform)\n",
    "\n",
    "def glorot_uniform(n_inputs,n_outputs,multiplier=1.0):\n",
    "    ''' Glorot uniform initialization '''\n",
    "    glorot = multiplier*np.sqrt(6.0/(n_inputs+n_outputs))\n",
    "    #Xavier_uniform\n",
    "    return np.random.uniform(-glorot,glorot,size=(n_inputs,n_outputs))\n",
    "\n",
    "def softmax(scores,temp=5.0): #normalized exponential function with temperature scaling to prevent overly confident prob. for high value scores.\n",
    "    ''' transforms scores to probabilites '''\n",
    "    exp = np.exp(np.array(scores)/temp)\n",
    "    return exp/exp.sum()\n",
    "\n",
    "class Agent(object):\n",
    "    ''' A Neural Network '''\n",
    "    #Activation= Tanh\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs, mutate_rate=.05, init_multiplier=1.0):\n",
    "        ''' Create agent's brain '''\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_outputs = n_outputs\n",
    "        self.mutate_rate = mutate_rate\n",
    "        self.init_multiplier = init_multiplier\n",
    "        self.network = {'Layer 1' : glorot_uniform(n_inputs, n_hidden,init_multiplier), #(25,512)\n",
    "                        'Bias 1'  : np.zeros((1,n_hidden)),\n",
    "                        'Layer 2' : glorot_uniform(n_hidden, n_outputs,init_multiplier), #(512,4)\n",
    "                        'Bias 2'  : np.zeros((1,n_outputs))}\n",
    "                        \n",
    "    def act(self, state):\n",
    "        ''' Use the network to decide on an action '''        \n",
    "        if(state.shape[0] != 1):\n",
    "            state = state.reshape(1,-1)\n",
    "        net = self.network\n",
    "        layer_one = np.tanh(np.matmul(state,net['Layer 1']) + net['Bias 1'])\n",
    "        layer_two = np.tanh(np.matmul(layer_one, net['Layer 2']) + net['Bias 2'])\n",
    "        return layer_two[0]\n",
    "    \n",
    "    def __add__(self, another):\n",
    "        ''' overloads the + operator for breeding '''\n",
    "        child = Agent(self.n_inputs, self.n_hidden, self.n_outputs, self.mutate_rate, self.init_multiplier)\n",
    "        for key in child.network:\n",
    "            n_inputs,n_outputs = child.network[key].shape\n",
    "            mask = np.random.choice([0,1],size=child.network[key].shape,p=[.5,.5])\n",
    "            random = glorot_uniform(mask.shape[0],mask.shape[1])\n",
    "            child.network[key] = np.where(mask==1,self.network[key],another.network[key])\n",
    "            mask = np.random.choice([0,1],size=child.network[key].shape,p=[1-self.mutate_rate,self.mutate_rate])\n",
    "            child.network[key] = np.where(mask==1,child.network[key]+random,child.network[key])\n",
    "        return child\n",
    "    \n",
    "def run_trial(env,agent,verbose=False):\n",
    "    ''' an agent performs 3 episodes of the env '''\n",
    "    totals = []\n",
    "    for _ in range(3):\n",
    "        state = env.reset()\n",
    "        if verbose: env.render()\n",
    "        total = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            state, reward, done, _ = env.step(agent.act(state))\n",
    "            if reward >= 100:\n",
    "                env.render()\n",
    "#             if verbose: env.render()\n",
    "            total += reward\n",
    "        totals.append(total)\n",
    "    return sum(totals)/3.0\n",
    "\n",
    "def next_generation(env,population,scores,temperature):\n",
    "    ''' breeds a new generation of agents '''\n",
    "    \n",
    "    scores, population =  zip(*sorted(zip(scores,population),reverse=True)) #sort scores and population w.r.t. scores.\n",
    "    #select the first 25% agents and mark as children \n",
    "    children = list(population[:len(population)//4])\n",
    "    #fill the remaining children with the best of parents.\n",
    "    #A random sample is generated from population,with probabilities returned from softmax.\n",
    "    #create 2 times the size of agents remaining after 25% children are removed.\n",
    "    parents = list(np.random.choice(population,size=2*(len(population)-len(children)),p=softmax(scores,temperature)))\n",
    "    #Breed between 2 Agent's from the above list and add it to the children list.\n",
    "    children = children + [parents[i]+parents[i+1] for i in range(0,len(parents)-1,2)]\n",
    "    #run the children agents and return children agents and their scores.\n",
    "    scores = [run_trial(env,agent) for agent in children]\n",
    "\n",
    "    return children,scores\n",
    "\n",
    "\n",
    "# def update_plot(graph, new_data):\n",
    "#     graph.set_xdata(np.append(graph.get_xdata(), new_data[0]))\n",
    "#     graph.set_ydata(np.append(graph.get_ydata(), new_data[1]))\n",
    "#     plt.draw()\n",
    "    \n",
    "def main():\n",
    "    ''' main function '''\n",
    "    graph = plt.plot([],[]) \n",
    "    # Setup environment\n",
    "    env = gym.make('BipedalWalker-v3')\n",
    "    env.seed(0)\n",
    "    np.random.seed(0)\n",
    "    genlist=[]\n",
    "    rewardlist=[]\n",
    "    # network params\n",
    "    n_inputs = env.observation_space.shape[0] # 24 observations\n",
    "    n_actions = env.action_space.shape[0] # 4 actions\n",
    "    n_hidden = 512 \n",
    "    multiplier = 5\n",
    "    \n",
    "    # Population params\n",
    "    pop_size = 50\n",
    "    mutate_rate = .1\n",
    "    softmax_temp = 5.0\n",
    "    \n",
    "    # Training\n",
    "    n_generations = 80\n",
    "    #create agents(as per population size)\n",
    "    population = [Agent(n_inputs,n_hidden,n_actions,mutate_rate,multiplier) for i in range(pop_size)]\n",
    "    #run all agents in the population\n",
    "    scores = [run_trial(env,agent) for agent in population]\n",
    "    #choose the best agent from the above trial and store it as best agent.\n",
    "    best = [deepcopy(population[np.argmax(scores)])]\n",
    "    #create new generation and repeat for n generations\n",
    "    for generation in range(n_generations):\n",
    "        #create next generation fromcurrent poulation and scores.\n",
    "        population,scores = next_generation(env,population, scores,softmax_temp)\n",
    "        best.append(deepcopy(population[np.argmax(scores)]))\n",
    "        print( \"Generation:\",generation,\"Score:\",np.max(scores))\n",
    "        genlist+=[generation]\n",
    "        rewardlist+=[np.max(scores)]\n",
    "        xpoints = np.array(genlist)\n",
    "        ypoints = np.array(rewardlist)\n",
    "        plt.plot(xpoints, ypoints)\n",
    "        plt.title(\"Genetic Algorithm\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        if generation>= 70:\n",
    "            plt.show()\n",
    "        #         data= (generation, np.max(scores))\n",
    "#         update_plot(graph,data)\n",
    "\n",
    "    # Record every agent\n",
    "    env = gym.wrappers.Monitor(env,'/monitor_output',force=True,video_callable=lambda episode_id: episode_id%3==0) #'/tmp/walker'   \n",
    "    for agent in best:\n",
    "        run_trial(env,agent)\n",
    "    env.close()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt-get -y install ffmpeg\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-removal",
   "metadata": {},
   "source": [
    "# 80 Gens\n",
    "Generation: 0 Score: -100.07884285899841\n",
    "Generation: 1 Score: -99.43141599802453\n",
    "Generation: 2 Score: -100.12341952465209\n",
    "Generation: 3 Score: -96.71923987511293\n",
    "Generation: 4 Score: -99.11920166116651\n",
    "Generation: 5 Score: -98.95568178070114\n",
    "Generation: 6 Score: -98.9472662677985\n",
    "Generation: 7 Score: -98.98570558711113\n",
    "Generation: 8 Score: -88.14688111204111\n",
    "Generation: 9 Score: -88.2564762022554\n",
    "Generation: 10 Score: -84.7208348704939\n",
    "Generation: 11 Score: -83.80718462162089\n",
    "Generation: 12 Score: -79.73696266731592\n",
    "Generation: 13 Score: -77.8271554940249\n",
    "Generation: 14 Score: -71.55715705891731\n",
    "Generation: 15 Score: -74.19425704477463\n",
    "Generation: 16 Score: -70.60125692234821\n",
    "Generation: 17 Score: -72.81263517808607\n",
    "Generation: 18 Score: -73.39610933036901\n",
    "Generation: 19 Score: -72.62448989932314\n",
    "Generation: 20 Score: -60.17841102360952\n",
    "Generation: 21 Score: -50.83967177233018\n",
    "Generation: 22 Score: -53.079412155855096\n",
    "Generation: 23 Score: -43.02773522030149\n",
    "Generation: 24 Score: -52.48782462556789\n",
    "Generation: 25 Score: -38.796501585152704\n",
    "Generation: 26 Score: -38.61967949881057\n",
    "Generation: 27 Score: 5.4382598812903495\n",
    "Generation: 28 Score: 2.9957253875354177\n",
    "Generation: 29 Score: 24.56730191511257\n",
    "Generation: 30 Score: 49.038023042851854\n",
    "Generation: 31 Score: 59.68679280720761\n",
    "Generation: 32 Score: 69.67381080529772\n",
    "Generation: 33 Score: 76.25514839279117\n",
    "Generation: 34 Score: 95.25026846769254\n",
    "Generation: 35 Score: 94.42016510715025\n",
    "Generation: 36 Score: 105.3570386195006\n",
    "Generation: 37 Score: 112.51350406123315\n",
    "Generation: 38 Score: 120.40496545562273\n",
    "Generation: 39 Score: 113.92486149263003\n",
    "Generation: 40 Score: 120.58434806004318\n",
    "Generation: 41 Score: 129.60969996593101\n",
    "Generation: 42 Score: 120.72116609801027\n",
    "Generation: 43 Score: 136.40006060636208\n",
    "Generation: 44 Score: 133.12543205231748\n",
    "Generation: 45 Score: 138.53658778073353\n",
    "Generation: 46 Score: 135.15193417422824\n",
    "Generation: 47 Score: 132.11102839953722\n",
    "Generation: 48 Score: 138.84261601353379\n",
    "Generation: 49 Score: 133.75285351567712\n",
    "Generation: 50 Score: 130.58514936695616\n",
    "Generation: 51 Score: 127.5330201450796\n",
    "Generation: 52 Score: 145.1527219184736\n",
    "Generation: 53 Score: 139.21306274901224\n",
    "Generation: 54 Score: 126.43323038921137\n",
    "Generation: 55 Score: 147.05425802377576\n",
    "Generation: 56 Score: 148.02307211698516\n",
    "Generation: 57 Score: 136.47115382257505\n",
    "Generation: 58 Score: 140.6853655456216\n",
    "Generation: 59 Score: 139.08807396004048\n",
    "Generation: 60 Score: 151.1514922793278\n",
    "Generation: 61 Score: 169.27609368724424\n",
    "Generation: 62 Score: 164.22981132748717\n",
    "Generation: 63 Score: 170.21954864385404\n",
    "Generation: 64 Score: 173.23744493530242\n",
    "Generation: 65 Score: 181.33300096010953\n",
    "Generation: 66 Score: 191.99886473225465\n",
    "Generation: 67 Score: 187.52284173382841\n",
    "Generation: 68 Score: 193.18610738116487\n",
    "Generation: 69 Score: 191.84656242112987\n",
    "Generation: 70 Score: 204.92281208467935\n",
    "Generation: 71 Score: 204.5231520498297\n",
    "Generation: 72 Score: 204.43940255886437\n",
    "Generation: 73 Score: 205.4166294884083\n",
    "Generation: 74 Score: 203.8942564385578\n",
    "Generation: 75 Score: 200.33575044396534\n",
    "Generation: 76 Score: 206.2069445875879\n",
    "Generation: 77 Score: 197.0496838699314\n",
    "Generation: 78 Score: 208.93788318464343\n",
    "Generation: 79 Score: 195.39179946800155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-guitar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
